import io
import os
import base64
import aiohttp
import asyncio
import mimetypes
import traceback

from PIL import Image
from uuid import uuid4
from pathlib import Path
from dotenv import load_dotenv
from typing import Any, Dict, List, Optional, Tuple
from openai import AsyncOpenAI

# chainlit
import chainlit as cl
from chainlit.logger import logger


load_dotenv(override=True)

# ìŒì‹ ì¹´í…Œê³ ë¦¬ ì •ì˜
FOOD_CATEGORIES = {
    "hamburger": ["í–„ë²„ê±°", "ë²„ê±°", "burger", "hamburger"],
    "meat": ["ê³ ê¸°", "ì‚¼ê²¹ì‚´", "ìŠ¤í…Œì´í¬", "meat", "steak", "pork", "beef", "ê°ˆë¹„", "êµ¬ì´"],
    "noodles": ["ë©´", "ë¼ë©´", "íŒŒìŠ¤íƒ€", "ë¼ë©˜", "noodle", "ramen", "pasta", "spaghetti", "ìš°ë™", "êµ­ìˆ˜"]
}


def _compose_guidance() -> str:
    input_path = os.environ.get("PROMPT_INPUT_PATH", "prompts/input.md")
    output_path = os.environ.get("PROMPT_OUTPUT_PATH", "prompts/output.md")
    input_text = Path(input_path).read_text(encoding="utf-8").strip()
    output_text = Path(output_path).read_text(encoding="utf-8").strip()
    parts = []
    if input_text:
        parts.append(f"[ì…ë ¥ ì§€ì¹¨]\n{input_text}")
    if output_text:
        parts.append(f"[ì¶œë ¥ ì§€ì¹¨]\n{output_text}")
    return "\n\n".join(parts).strip()


async def _read_file_bytes(file) -> bytes:
    logger.info("_read_file_bytes ì‹œì‘")
    
    # content ì†ì„± í™•ì¸
    if hasattr(file, "content") and file.content:
        logger.info("file.content ë°œê²¬")
        if isinstance(file.content, (bytes, bytearray)):
            logger.info(f"bytes/bytearray í˜•ì‹: {len(file.content)} bytes")
            return bytes(file.content)
        if hasattr(file.content, "read"):
            logger.info("file.content.read() ì‚¬ìš©")
            data = file.content.read()
            logger.info(f"ì½ì€ ë°ì´í„°: {len(data)} bytes")
            return data

    # path ì†ì„± í™•ì¸
    file_path = getattr(file, "path", None)
    if file_path:
        logger.info(f"file.path ë°œê²¬: {file_path}")
        if os.path.exists(file_path):
            logger.info(f"íŒŒì¼ ì¡´ì¬ í™•ì¸, ì½ê¸° ì‹œì‘")
            data = await asyncio.to_thread(Path(file_path).read_bytes)
            logger.info(f"íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(data)} bytes")
            return data
        else:
            logger.warning(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")

    # url ì†ì„± í™•ì¸
    file_url = getattr(file, "url", None)
    if file_url:
        logger.info(f"file.url ë°œê²¬: {file_url}")
        async with aiohttp.ClientSession() as session:
            async with session.get(file_url) as resp:
                resp.raise_for_status()
                data = await resp.read()
                logger.info(f"URLì—ì„œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(data)} bytes")
                return data

    logger.error("ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ì—†ìŒ")
    logger.error(f"íŒŒì¼ ì†ì„±: {dir(file)}")
    raise ValueError("ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def _detect_food_category(analysis_text: str) -> Optional[str]:
    """ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ ìŒì‹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
    
    Returns:
        ì¹´í…Œê³ ë¦¬ í‚¤ ("hamburger", "meat", "noodles") ë˜ëŠ” None
    """
    text_lower = analysis_text.lower()
    
    for category, keywords in FOOD_CATEGORIES.items():
        for keyword in keywords:
            if keyword.lower() in text_lower:
                logger.info(f"ìŒì‹ ì¹´í…Œê³ ë¦¬ ê°ì§€: {category} (í‚¤ì›Œë“œ: {keyword})")
                return category
    
    logger.info("ìŒì‹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return None


async def _load_reference_images(category: str) -> Tuple[List[str], List[str]]:
    """í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì°¸ì¡° ì´ë¯¸ì§€ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        category: "hamburger", "meat", "noodles" ì¤‘ í•˜ë‚˜
        
    Returns:
        (good_image_urls, bad_image_urls) íŠœí”Œ
    """
    good_images: List[str] = []
    bad_images: List[str] = []
    
    base_path = Path("public/reference_images") / category
    
    # good í´ë”ì˜ ì´ë¯¸ì§€ ë¡œë“œ
    good_dir = base_path / "good"
    if good_dir.exists():
        for img_path in good_dir.glob("*"):
            if img_path.suffix.lower() in [".jpg", ".jpeg", ".png", ".gif", ".webp", ".bmp"]:
                try:
                    img_bytes = await asyncio.to_thread(img_path.read_bytes)
                    # MIME íƒ€ì… ì¶”ë¡ 
                    try:
                        with Image.open(io.BytesIO(img_bytes)) as pil_img:
                            mime_type = Image.MIME.get(pil_img.format, "image/jpeg")
                    except Exception:
                        mime_type = "image/jpeg"
                    
                    img_b64 = base64.b64encode(img_bytes).decode("utf-8")
                    data_url = f"data:{mime_type};base64,{img_b64}"
                    good_images.append(data_url)
                    logger.info(f"ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ (good): {img_path.name}")
                except Exception as e:
                    logger.error(f"ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ (good/{img_path.name}): {e}")
    
    # bad í´ë”ì˜ ì´ë¯¸ì§€ ë¡œë“œ
    bad_dir = base_path / "bad"
    if bad_dir.exists():
        for img_path in bad_dir.glob("*"):
            if img_path.suffix.lower() in [".jpg", ".jpeg", ".png", ".gif", ".webp", ".bmp"]:
                try:
                    img_bytes = await asyncio.to_thread(img_path.read_bytes)
                    # MIME íƒ€ì… ì¶”ë¡ 
                    try:
                        with Image.open(io.BytesIO(img_bytes)) as pil_img:
                            mime_type = Image.MIME.get(pil_img.format, "image/jpeg")
                    except Exception:
                        mime_type = "image/jpeg"
                    
                    img_b64 = base64.b64encode(img_bytes).decode("utf-8")
                    data_url = f"data:{mime_type};base64,{img_b64}"
                    bad_images.append(data_url)
                    logger.info(f"ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ (bad): {img_path.name}")
                except Exception as e:
                    logger.error(f"ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ (bad/{img_path.name}): {e}")
    
    logger.info(f"ì¹´í…Œê³ ë¦¬ '{category}': good {len(good_images)}ì¥, bad {len(bad_images)}ì¥ ë¡œë“œ ì™„ë£Œ")
    return good_images, bad_images


def _extract_text_from_response(response: Dict[str, Any]) -> str:

    outputs: List[Dict[str, Any]] = response.get("output", []) or []
    if not outputs:
        outputs = response.get("choices", [])  # fallback shape

    collected: List[str] = []
    for item in outputs:
        contents = item.get("content", []) if isinstance(item, dict) else []
        for part in contents:
            if not isinstance(part, dict):
                continue
            part_type = part.get("type")
            if part_type in {"output_text", "text"}:
                collected.append(part.get("text", ""))
            elif part_type == "message":
                nested_content = part.get("content", [])
                for nested in nested_content:
                    if nested.get("type") in {"output_text", "text"}:
                        collected.append(nested.get("text", ""))

    text = "\n".join(filter(None, (segment.strip() for segment in collected)))
    return text.strip()


async def _analyze_image_with_vision_api(prompt: str, image_data_url: str) -> str:
    api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("VISION_API_KEY")
    model = (
        os.environ.get("VISION_MODEL")
        or os.environ.get("OPENAI_VISION_MODEL")
        or "gpt-4.1-mini"
    )
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ë˜ëŠ” VISION_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    base_url = (
        os.environ.get("OPENAI_BASE_URL")
        or os.environ.get("VISION_API_BASE_URL")
        or "https://api.openai.com/v1"
    ).rstrip("/")

    extra_headers: Dict[str, str] = {}
    if "openai.com" in base_url:
        extra_headers["OpenAI-Beta"] = "assistants=v2"

    client = AsyncOpenAI(api_key=api_key, base_url=base_url, default_headers=extra_headers or None)

    resp = await client.responses.create(
        model=model,
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt},
                    {"type": "input_image", "image_url": image_data_url},
                ],
            }
        ],
        max_output_tokens=2048,
    )

    text = getattr(resp, "output_text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        body = resp.model_dump()  # type: ignore[attr-defined]
    except Exception:
        try:
            body = resp.__dict__
        except Exception:
            body = {}

    analysis = _extract_text_from_response(body)
    if not analysis:
        raise RuntimeError("ë¹„ì „ API ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return analysis


async def _analyze_with_reference_images(
    user_image_urls: List[str],
    category: str,
    base_prompt: str
) -> str:
    """ì‚¬ìš©ì ì´ë¯¸ì§€ì™€ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        user_image_urls: ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ data URL ë¦¬ìŠ¤íŠ¸
        category: ìŒì‹ ì¹´í…Œê³ ë¦¬ ("hamburger", "meat", "noodles")
        base_prompt: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        
    Returns:
        ë¹„êµ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ
    good_refs, bad_refs = await _load_reference_images(category)
    
    if not good_refs and not bad_refs:
        logger.warning(f"ì¹´í…Œê³ ë¦¬ '{category}'ì˜ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ë¶„ì„ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        if len(user_image_urls) == 1:
            return await _analyze_image_with_vision_api(base_prompt, user_image_urls[0])
        else:
            return await _analyze_images_with_vision_api(base_prompt, user_image_urls)
    
    # ë¹„êµ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    category_names = {
        "hamburger": "í–„ë²„ê±°",
        "meat": "ê³ ê¸°ë¥˜",
        "noodles": "ë©´ë¥˜"
    }
    category_name = category_names.get(category, category)
    
    comparison_prompt = f"""ë‹¹ì‹ ì€ ìŒì‹ ì‚¬ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ {category_name} ì‚¬ì§„ì„ ë¶„ì„í•˜ê³ , ì œê³µëœ ì°¸ì¡° ì´ë¯¸ì§€ë“¤ê³¼ ë¹„êµí•˜ì—¬ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìˆœì„œ:**
1. ë¨¼ì € ì‚¬ìš©ìì˜ ì‚¬ì§„ì„ ë¶„ì„í•©ë‹ˆë‹¤.
2. "ì˜ ì°íŒ ì˜ˆì‹œ" ì´ë¯¸ì§€ë“¤ê³¼ ë¹„êµí•˜ì—¬ ì–´ë–¤ ì ì´ ì¢‹ê³  ì–´ë–¤ ì ì´ ë¶€ì¡±í•œì§€ ì„¤ëª…í•©ë‹ˆë‹¤.
3. "ëª» ì°íŒ ì˜ˆì‹œ" ì´ë¯¸ì§€ë“¤ê³¼ ë¹„êµí•˜ì—¬ ìœ ì‚¬í•œ ì‹¤ìˆ˜ë¥¼ í”¼í•˜ê¸° ìœ„í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
4. êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ê°œì„  ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

**í‰ê°€ ê¸°ì¤€:**
- êµ¬ë„ ë° í”„ë ˆì´ë°
- ì¡°ëª… (ìì—°ê´‘/ì¸ê³µê´‘)
- ì´ˆì  ë° ì„ ëª…ë„
- ë°°ê²½ ì •ë¦¬ ë° ë¶„ìœ„ê¸°
- ìƒ‰ê° ë° ëŒ€ë¹„

**ì‚¬ìš©ì ìš”ì²­:**
{base_prompt}

**ì°¸ì¡° ì´ë¯¸ì§€ êµ¬ì„±:**
- ì˜ ì°íŒ ì˜ˆì‹œ: {len(good_refs)}ì¥
- ëª» ì°íŒ ì˜ˆì‹œ: {len(bad_refs)}ì¥

ì•„ë˜ ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ê°€ ì œê³µë©ë‹ˆë‹¤:
1. ì‚¬ìš©ì ì‚¬ì§„ ({len(user_image_urls)}ì¥)
2. ì˜ ì°íŒ ì˜ˆì‹œ ({len(good_refs)}ì¥)
3. ëª» ì°íŒ ì˜ˆì‹œ ({len(bad_refs)}ì¥)
"""
    
    # API í‚¤ ë° ëª¨ë¸ ì„¤ì •
    api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("VISION_API_KEY")
    model = (
        os.environ.get("VISION_MODEL")
        or os.environ.get("OPENAI_VISION_MODEL")
        or "gpt-4.1-mini"
    )
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ë˜ëŠ” VISION_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    base_url = (
        os.environ.get("OPENAI_BASE_URL")
        or os.environ.get("VISION_API_BASE_URL")
        or "https://api.openai.com/v1"
    ).rstrip("/")

    extra_headers: Dict[str, str] = {}
    if "openai.com" in base_url:
        extra_headers["OpenAI-Beta"] = "assistants=v2"

    client = AsyncOpenAI(api_key=api_key, base_url=base_url, default_headers=extra_headers or None)

    # content íŒŒíŠ¸ êµ¬ì„±: prompt + ì‚¬ìš©ì ì´ë¯¸ì§€ + ì°¸ì¡° ì´ë¯¸ì§€(good) + ì°¸ì¡° ì´ë¯¸ì§€(bad)
    content_parts: List[Dict[str, Any]] = [{"type": "input_text", "text": comparison_prompt}]
    
    # ì‚¬ìš©ì ì´ë¯¸ì§€ ì¶”ê°€
    for url in user_image_urls:
        content_parts.append({"type": "input_image", "image_url": url})
    
    # ì˜ ì°íŒ ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€
    for url in good_refs:
        content_parts.append({"type": "input_image", "image_url": url})
    
    # ëª» ì°íŒ ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€
    for url in bad_refs:
        content_parts.append({"type": "input_image", "image_url": url})
    
    logger.info(f"ë¹„êµ ë¶„ì„ ìš”ì²­: ì‚¬ìš©ì {len(user_image_urls)}ì¥ + ì°¸ì¡°(good) {len(good_refs)}ì¥ + ì°¸ì¡°(bad) {len(bad_refs)}ì¥")

    resp = await client.responses.create(
        model=model,
        input=[
            {
                "role": "user",
                "content": content_parts,
            }
        ],
        max_output_tokens=3072,  # ë¹„êµ ë¶„ì„ì€ ë” ê¸´ ì‘ë‹µì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
    )

    text = getattr(resp, "output_text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        body = resp.model_dump()  # type: ignore[attr-defined]
    except Exception:
        try:
            body = resp.__dict__
        except Exception:
            body = {}

    analysis = _extract_text_from_response(body)
    if not analysis:
        raise RuntimeError("ë¹„ì „ API ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return analysis


async def _analyze_images_with_vision_api(prompt: str, image_data_urls: List[str]) -> str:
    """ì—¬ëŸ¬ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ë¶„ì„í•©ë‹ˆë‹¤.

    - prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ + ê°€ì´ë“œë¼ì¸
    - image_data_urls: data:<mime>;base64,<payload> í˜•íƒœì˜ URL ë¦¬ìŠ¤íŠ¸

    í•˜ë‚˜ì˜ ìš”ì²­ìœ¼ë¡œ input_text ë‹¤ìŒì— ì—¬ëŸ¬ ê°œì˜ input_image íŒŒíŠ¸ë¥¼ ë¶™ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    if not image_data_urls:
        raise ValueError("ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("VISION_API_KEY")
    model = (
        os.environ.get("VISION_MODEL")
        or os.environ.get("OPENAI_VISION_MODEL")
        or "gpt-4.1-mini"
    )
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ë˜ëŠ” VISION_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    base_url = (
        os.environ.get("OPENAI_BASE_URL")
        or os.environ.get("VISION_API_BASE_URL")
        or "https://api.openai.com/v1"
    ).rstrip("/")

    extra_headers: Dict[str, str] = {}
    if "openai.com" in base_url:
        extra_headers["OpenAI-Beta"] = "assistants=v2"

    client = AsyncOpenAI(api_key=api_key, base_url=base_url, default_headers=extra_headers or None)

    # content íŒŒíŠ¸ êµ¬ì„±: ì²« íŒŒíŠ¸ëŠ” input_text, ì´ì–´ì„œ ëª¨ë“  input_image
    content_parts: List[Dict[str, Any]] = [{"type": "input_text", "text": prompt}]
    for url in image_data_urls:
        content_parts.append({"type": "input_image", "image_url": url})

    resp = await client.responses.create(
        model=model,
        input=[
            {
                "role": "user",
                "content": content_parts,
            }
        ],
        max_output_tokens=2048,
    )

    text = getattr(resp, "output_text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        body = resp.model_dump()  # type: ignore[attr-defined]
    except Exception:
        try:
            body = resp.__dict__
        except Exception:
            body = {}

    analysis = _extract_text_from_response(body)
    if not analysis:
        raise RuntimeError("ë¹„ì „ API ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return analysis


@cl.on_chat_start
async def on_chat_start():
    logger.info("Chat session started")
    cl.user_session.set("track_id", str(uuid4()))
    cl.user_session.set("current_text_msg", None)
    cl.user_session.set("current_image_name", None)
    cl.user_session.set("current_image_data_url", None)  # í•˜ìœ„ í˜¸í™˜(ë‹¨ì¼ ì´ë¯¸ì§€)
    cl.user_session.set("current_image_names", [])
    cl.user_session.set("current_image_data_urls", [])
    return True


@cl.on_message
async def on_message(message: cl.Message):
    try:
        # ì´ë¯¸ì§€ ì²˜ë¦¬ - elements ì†ì„±ê³¼ ì²¨ë¶€ íŒŒì¼ ëª¨ë‘ í™•ì¸
        files = []
        
        # message.elements í™•ì¸ (Chainlit êµ¬ë²„ì „)
        if hasattr(message, 'elements') and message.elements:
            files = message.elements
            logger.info(f"message.elementsì—ì„œ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        # attachments í™•ì¸ (Chainlit ì‹ ë²„ì „)
        if not files and hasattr(message, 'attachments') and message.attachments:
            files = message.attachments
            logger.info(f"message.attachmentsì—ì„œ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ì´ë¯¸ì§€ ì²˜ë¦¬
        if files:
            logger.info(f"ì´ {len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
            await _handle_image_upload(message, files)
            return

        # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
        await _handle_text_message(message)

    except Exception as e:
        logger.error(f"Error in on_message: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        await cl.ErrorMessage(
            content=f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).send()


async def _handle_image_upload(message: cl.Message, files):
    image_entries: List[Dict[str, Any]] = []  # {name, url}
    
    logger.info(f"_handle_image_upload í˜¸ì¶œë¨: {len(files)}ê°œ íŒŒì¼")

    # 1) ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì¤‘ ì´ë¯¸ì§€ë§Œ ì¶”ì¶œí•˜ì—¬ data URL ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    for idx, file in enumerate(files):
        try:
            logger.info(f"íŒŒì¼ {idx+1} ì²˜ë¦¬ ì¤‘...")
            
            # íŒŒì¼ ì†ì„± í™•ì¸
            file_name = getattr(file, "name", None) or getattr(file, "filename", None) or "ì•Œ ìˆ˜ ì—†ìŒ"
            file_path = getattr(file, "path", None)
            file_url = getattr(file, "url", None)
            mime_type = getattr(file, "mime", None) or getattr(file, "type", None) or ""
            
            logger.info(f"íŒŒì¼ëª…: {file_name}, MIME: {mime_type}, ê²½ë¡œ: {file_path}, URL: {file_url}")
            
            file_source = file_path if file_path else file_url
            extension = Path(file_name).suffix.lower() if file_name else ""
            source_mime = (
                mimetypes.guess_type(file_source)[0]
                if isinstance(file_source, str)
                else ""
            )

            image_extensions = {".jpg", ".jpeg", ".png", ".gif", ".webp", ".bmp"}
            is_image = mime_type.startswith("image/") or extension in image_extensions

            if not is_image and source_mime:
                is_image = source_mime.startswith("image/")

            image_bytes = None

            if is_image:
                image_bytes = await _read_file_bytes(file)
            else:
                # MIMEì´ ë¹„ì–´ìˆì–´ë„ ì‹¤ì œë¡œ ì´ë¯¸ì§€ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì‹œë„í•´ ë³¸ë‹¤.
                try:
                    candidate_bytes = await _read_file_bytes(file)
                    with Image.open(io.BytesIO(candidate_bytes)) as pil_image:
                        detected_format = pil_image.format
                    if detected_format:
                        mime_type = Image.MIME.get(detected_format.upper(), "")
                        image_bytes = candidate_bytes
                        is_image = True
                except Exception:
                    image_bytes = None

            if is_image and image_bytes:
                logger.info(f"ì´ë¯¸ì§€ë¡œ í™•ì¸ë¨: {file_name} ({len(image_bytes)} bytes)")
                
                if not mime_type:
                    try:
                        with Image.open(io.BytesIO(image_bytes)) as pil_image:
                            detected_format = pil_image.format
                        if detected_format:
                            mime_type = Image.MIME.get(detected_format.upper(), "")
                    except Exception:
                        mime_type = ""

                if not mime_type:
                    mime_type = (
                        mimetypes.guess_type(file_name)[0]
                        or source_mime
                        or "image/jpeg"
                    )

                image_b64 = base64.b64encode(image_bytes).decode("utf-8")
                image_data_url = f"data:{mime_type};base64,{image_b64}"

                image_entries.append({"name": file_name, "url": image_data_url})
                logger.info(f"ì´ë¯¸ì§€ ì¶”ê°€ ì™„ë£Œ: {file_name}")
            else:
                logger.warning(f"ì´ë¯¸ì§€ê°€ ì•„ë‹ˆê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨: {file_name}")

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            try:
                logger.error(f"íŒŒì¼ ì •ë³´: {getattr(file, '__dict__', {})}")
            except Exception:
                pass

    # 2) ìµœì†Œ 1ì¥ ì´ìƒì¸ì§€ í™•ì¸
    logger.info(f"ì´ {len(image_entries)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
    
    if not image_entries:
        await cl.ErrorMessage(content="ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.").send()
        return

    # 3) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_message = (message.content or "").strip()
    prompt_sections = []
    if user_message:
        prompt_sections.append(user_message)
    prompt_sections.append(_compose_guidance())
    prompt = "\n\n".join(prompt_sections)

    # 4) ì„¸ì…˜ì— ì €ì¥ (ë¦¬ìŠ¤íŠ¸)
    names = [e["name"] for e in image_entries]
    urls = [e["url"] for e in image_entries]
    cl.user_session.set("current_image_names", names)
    cl.user_session.set("current_image_data_urls", urls)

    # í•˜ìœ„ í˜¸í™˜: ë‹¨ì¼ í‚¤ì—ë„ ì²« ì¥ì„ ê¸°ë¡
    cl.user_session.set("current_image_name", names[0])
    cl.user_session.set("current_image_data_url", urls[0])
    cl.user_session.set("is_text_input", True)

    # 5) 1ì°¨ ë¶„ì„ ìš”ì²­
    try:
        count = len(urls)
        prefix = f"ğŸ” ì´ë¯¸ì§€ {count}ì¥ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦" if count > 1 else "ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦"
        typing_msg = cl.Message(content=f"{prefix} ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.", author="assistant")
        await typing_msg.send()

        # 1ì°¨ ë¶„ì„ (ì¹´í…Œê³ ë¦¬ ê°ì§€ë¥¼ ìœ„í•´)
        if len(urls) == 1:
            initial_analysis = await _analyze_image_with_vision_api(prompt, urls[0])
        else:
            initial_analysis = await _analyze_images_with_vision_api(prompt, urls)

        typing_msg.content = initial_analysis
        await typing_msg.update()
        
        # 6) ìŒì‹ ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° ì°¸ì¡° ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„
        detected_category = _detect_food_category(initial_analysis)
        
        if detected_category:
            logger.info(f"ìŒì‹ ì¹´í…Œê³ ë¦¬ '{detected_category}' ê°ì§€ë¨. ì°¸ì¡° ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            
            # ë¹„êµ ë¶„ì„ ì§„í–‰ ë©”ì‹œì§€
            comparison_msg = cl.Message(
                content=f"ğŸ“¸ ì°¸ì¡° ì´ë¯¸ì§€ì™€ ë¹„êµ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.",
                author="assistant"
            )
            await comparison_msg.send()
            
            try:
                # ì°¸ì¡° ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë¹„êµ ë¶„ì„
                comparison_result = await _analyze_with_reference_images(
                    user_image_urls=urls,
                    category=detected_category,
                    base_prompt=prompt
                )
                
                comparison_msg.content = f"## ğŸ“Š ì°¸ì¡° ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ê²°ê³¼\n\n{comparison_result}"
                await comparison_msg.update()
                
            except Exception as comp_error:
                logger.error(f"ì°¸ì¡° ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {comp_error}")
                comparison_msg.content = f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {comp_error}"
                await comparison_msg.update()
        else:
            logger.info("íŠ¹ì • ìŒì‹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ë¶„ì„ ê²°ê³¼ë§Œ ì œê³µí•©ë‹ˆë‹¤.")
            
    except Exception as analysis_error:
        logger.error(f"ë¹„ì „ API ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {analysis_error}")
        try:
            typing_msg.content = f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_error}"
            await typing_msg.update()
        except Exception:
            await cl.ErrorMessage(
                content=f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_error}"
            ).send()


async def _handle_text_message(message: cl.Message):
    urls: List[str] = cl.user_session.get("current_image_data_urls") or []
    single_url = cl.user_session.get("current_image_data_url")

    # ë‹¨ì¼ í‚¤ë§Œ ì¡´ì¬í•˜ê³  ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆë‹¤ë©´ ë³´ê°•
    if not urls and single_url:
        urls = [single_url]

    if urls:
        # ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° - ì´ë¯¸ì§€ ì¬ë¶„ì„
        try:
            prompt_sections = []
            if message.content:
                prompt_sections.append(message.content.strip())
            prompt_sections.append(_compose_guidance())
            analysis_prompt = "\n\n".join(filter(None, prompt_sections))

            cl.user_session.set("is_text_input", True)
            count = len(urls)
            prefix = f"ğŸ” ì´ë¯¸ì§€ {count}ì¥ ì¬ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦" if count > 1 else "ğŸ” ì´ë¯¸ì§€ ì¬ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦"
            typing_msg = cl.Message(content=f"{prefix} ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.", author="assistant")
            await typing_msg.send()

            if len(urls) == 1:
                analysis_text = await _analyze_image_with_vision_api(
                    analysis_prompt, urls[0]
                )
            else:
                analysis_text = await _analyze_images_with_vision_api(
                    analysis_prompt, urls
                )

            typing_msg.content = analysis_text
            await typing_msg.update()
        except Exception as analysis_error:
            logger.error(f"ë¹„ì „ API ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {analysis_error}")
            try:
                typing_msg.content = f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_error}"
                await typing_msg.update()
            except Exception:
                await cl.ErrorMessage(
                    content=f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_error}"
                ).send()
    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ì œê³µ
        if_wrong_input_path = os.environ.get("PROMPT_IF_WRONG_INPUT_PATH", "prompts/if_wrong_input.md")
        tip = Path(if_wrong_input_path).read_text(encoding="utf-8").strip()
        await cl.Message(content=tip, author="assistant").send()
